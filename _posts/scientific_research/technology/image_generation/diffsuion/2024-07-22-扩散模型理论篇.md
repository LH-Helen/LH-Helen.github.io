---
title:  "「扩散模型」 Diffusion Model 理论篇"
mathjax: true
key: diffusion_study
toc: true
toc_sticky: true
category: [scientific_research, image_generation, diffusion]
---
<span id='head'></span>

# 扩散模型理论篇——发疯整理版

闲谈叨叨叨：

> 哇塞，怎么要学的东西那么多！想学习扩散模型，结果看资料开头就讲到VAE，不懂...，好！学VAE！结果KL散度到底是什么！怎么这么多概率公式啊！（抓狂）。没办法，还是了解下吧...
>
> 这篇文章是整个扩散模型学习过程的笔记记录（还有发疯式的心路历程o((>ω< ))o）。尽量整理的知识点全面一点，和大家一起学习！强烈建议先复习复习**概率论**！

目录附上：





## 1 补充一些知识点

> 这一部分如果都了解过，那就忽略掉。不想忽略的，可以在看正文部分涉及到时来翻一翻。（把这一部分放在前面，是因为怕你们坚持不到最后(*/ω＼*)）

概率的东西，大家还记否？如果想推公式的话，建议复习一下。我先列几个可能会用到的公式，按需查看。

### 1.1 一些公式

#### 1.1.1 条件概率的一般形式

$$
\begin{aligned}
&P(A,B,C) = P(C|B,A)P(B,A)=P(C|B,A)P(B|A)P(A)\\
&P(B,C|A)=P(B|A)P(C|A,B)
\end{aligned}
$$

嗯~，能看懂哈＜（＾－＾）＞

#### 1.1.2 基于马尔科夫假设的条件概率

如果满足马尔科夫链关系$A\rightarrow{B}\rightarrow{C}$，那么有

$$
\begin{aligned}
&P(A,B,C) = P(C|B,A)P(B,A) = P(C|B)P(B|A)P(A)\\
&P(B,C|A)=P(B|A)P(C|B)
\end{aligned}
$$

就是A距离C太过遥远，C已经不记得A了，所以A对C的影响没那么大了的意思。

#### 1.1.3 函数的期望

已知概率密度函数$p(x)$，那$x$的期望就是

$$
\begin{aligned}
\mathbb{E}\[x\] &= \int xp(x)dx \\
&\approx \sum^n_{i=1}x_ip(x_i)(x_i-x_{i-1}),\quad(x_0<x_1<\cdots<x_n) \\
&\approx \frac{1}{n}\sum^n_{i=1}x_i,\quad x_i\sim p(x)
\end{aligned}
$$

第一行就是那个函数期望公式。第二行代表的是数值积分，就是求函数与x轴的面积的那个意义。第三行是采样计算，采样出若干个点算平均值，这个没有用到概率，但是采样出来的数据已经有概率意义了，就是概率大的多出现、概率小的出现次数也少。

那想必下面这个公式，大家应该还有印象吧。

$$
\mathbb{E}_{x \sim p(x)}[f(x)]= \int f(x)p(x)dx \approx \frac{1}{n} \sum^n_{i=1}f(x_i), \quad x_i \sim p(x)
$$


### 1.2 KL散度

> 参考：[初学机器学习：直观解读KL散度的数学概念 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/37452654)
>
> 文章里的例子很贴切，公式解释挺好理解的，通俗易懂。这里我就只列一下定义公式，不做过多解释了。

#### 1.2.1 KL散度

KL散度（Kullback-Leibler Divergence）：用来衡量两个分布（比如两条直线之间的匹配程度的方法）

定义公式：

$$
\begin{aligned}
D_{KL}(p||q) &= \sum^{N}_{i=1} \bigg[ p(x_{i}) log \frac{p(x_{i})}{q(x_{i})} \bigg] \\
&= \int p(x) ln \frac{p(x)}{q(x)} dx \\
&= \mathbb{E}_{x \sim p(x)}\bigg[ log\frac{p(x)}{q(x)} \bigg]
\end{aligned} \\
$$

其中，$q(x)$是近似分布，$p(x)$是想要用$q(x)$拟合的真实分布。所以如果两个分布完全匹配的话，应该是$D_{KL}(p||q)=0$. 所以KL散度越小越好，也就是近似分布与真实分布匹配的就越好。后面两行后面扩散模型公式推导会用到。

这里注意一下，$D_{KL}(p||q) \neq D_{KL}(q||p)$，毕竟公式里的$p$和$q$的位置也不一样嘛。$D_{KL}(p||q)$我们叫它前向KL散度，$D_{KL}(q||p)$是反向KL散度。（这个有需要的时候再扩展吧。）

#### 1.2.2 高斯分布的KL散度

假设分布$p$和$q$满足高斯分布，那它们的KL散度的公式就可以写成下面的形式。（推导过程就不写了，有yi点麻烦）

$$
KL(p,q)=log\frac{\sigma_2}{\sigma_1}+\frac{\sigma_1^2+(\mu_1-\mu_2)^2}{2\sigma_2^2}-\frac{1}{2}
$$

（还记得啥是正态分布...吧...，我相信你记得！）

$$
f(x)=\frac{1}{\sqrt{2\pi}\sigma}exp\bigg(-\frac{(x-\mu)^2}{2\sigma^2}\bigg)
, \quad 
\sigma = \sqrt{\frac{\sum^{n}_{i=1}(x_i-\mu)^2}{n}}
$$


### 1.3 VAE

> VAE它来了！想必涉猎过生成模型的都听过它的大名吧。之前搞GAN的时候听过但没打算学，结果扩散模型火了，又提到VAE，那就了解了解吧，总得知道谁为啥好，好在哪里，谁有啥不好，不好在哪里。（怎么越学越多啊o(≧口≦)o

> 参考：[变分自编码器（一）：原来是这么一回事 - 科学空间|Scientific Spaces (kexue.fm)](https://kexue.fm/archives/5253)
>
> 整个讲解浅显易懂，尤其是VAE的发展过程，涉及到的公式的含义，讲的挺清晰的，建议大家细细品读。这篇文章：[变分自编码器（二）：从贝叶斯观点出发 - 科学空间|Scientific Spaces (kexue.fm)](https://kexue.fm/archives/5343)，我觉得也得好好看看，里面的概念和公式推导对之后扩散模型公式理解挺有帮助的。

#### 1.3.1 单层VAE

接下来就用我自己的话大致解释一下VAE是怎么回事。

VAE毕竟也是个生成模型，那生成器是要有的。那用谁来生成？生成之后跟谁比较然后优化呢？VAE的思路是，用我手里的数据$X$（真实样本）去拟合一个分布$p(X)$，然后根据$p(X)$采样出来数据$Z$，通过生成器$g(Z)$生成$\hat{X}$，用$\hat{X}$去与$X$对比，也就是希望把开始的$X$给还原回来。大概就是这么个思路。苏神画了VAE的结构图，挺好理解的，对吧！

<center class="half">
  <img src="https://kexue.fm/usr/uploads/2018/03/4168876662.png" height="400"/>&emsp;
</center>


上面这个图当中，有几个点需要注意：

- VAE为每个样本构造了专属于该样本的正态分布，然后采样来重构。

  - 这个涉及到后验分布。不是假设$p(Z)$是正态分布的，而是假设$p(Z|X)$（后验分布）是正态分布，可以理解吗？就是我在知道X的情况Z的概率属于正态分布，这个情况就是后验分布。因为如果直接假设$p(Z)$是正态分布，采样得到若干$Z$，然后生成$\hat{X}$，我i们不能判断$\hat{X}$与原数据$X$的分布是否一样，毕竟原数据的分布我们不知道。

  - 至于为什么要专属的呢，是因为我们希望的是由$X$样本采样出来$Z$，能够还原为$X$，就是一对一的关系，避免我随便一个$Z$生成的$\hat{X}$不知道对应着哪个$X$.

  - 还有为什么是正态分布呢？这就又要提到KL散度了，所以为什么用到KL散度了呢？... （啊啊啊啊~怎么这么多问题！一会儿再讲！冷静！慢慢来！先往下看！我会提醒你的:)

  - 你先假设，假设是正态分布。

- 均值方差计算模块产生各个样本的均值和方差。这里均值就代表着采样得到的结果，方差就是噪声。

  - 这里的采样结果$Z$是有均值和方差共同影响生成的。训练希望$\hat{X}$接近$X$，那也就意味着，希望噪声没那么强，想让噪声越小越好。但是没有噪声，那得到也只是个确定的结果，也不就没有生成的意义了嘛。

  - VAE为了防止噪声为0，保证生成的能力。规定$p(Z|X)$接近标准正态分布$\mathcal{N}(0,I)$。这里就比较巧妙，先放推导公式：
    $$
    \begin{aligned}
    p(Z) &= \sum_{X}p(Z|X)p(X) \\
    &= \sum_{X}\mathcal{N}(0,I)p(X) \\
    &= \mathcal{N}(0,I)\sum_{X}p(X) \\
    &= \mathcal{N}(0,I)
    \end{aligned}
    $$
    还记得之前说过的先验分布和后验分布吧。你想想看，在规定$p(Z|X)$接近标准正态分布$\mathcal{N}(0,I)$后，先验分布$p(Z)$也满足了正态分布，那是不是就意味着，我们就只是从一个正态分布中采样出来若干个$Z$，这些$Z$也满足正态分布，确确实实地保留着随机性。同时我们也可以判断由$Z$生成的$\hat{X}$与原数据$X$的分布是否一样，因为都是接近正态分布的嘛。

    > 妙啊！兜来兜去又转回来了！（要是没有理解我的解释的话，可以去看一下原文，会讲的更详细一点）

  - 那怎么样让$p(Z|X)$接近标准正态分布$\mathcal{N}(0,I)$呢？KL散度来啦！用$KL\bigg(\mathcal{N}(\mu,\sigma^2)||\mathcal{N}(0,I)\bigg)$来作为额外的loss。

    至于之前问为什么选择正态分布，也是与KL散度有关系，因为公式中存在除法，会涉及到分母为零的情况。正态分布所有点的概率密度都是非负的，所以就避免了这个问题。

    > 这一部分的公式推导很多，但是我感觉目前不用了解太详细。毕竟VAE在这里只是补充了解的作用。如果想深入学习的话，看原文！

下面这张图我觉得挺好的，贴上来看看。

<center class="half">
  <img src="https://kexue.fm/usr/uploads/2018/03/2674220095.png" height="400"/>&emsp;
</center>

其实VAE里也有所谓对抗的过程，之前提到希望$\hat{X}$接近$X$就让噪声越小越好，但是KL Loss又希望有高斯噪声去接近正态分布。这就是一个对抗的过程，但是是共同进步的。与GAN不同，GAN是在训练生成器G的时候，将判别器D冻住。

VAE大概就是这样啦！(o゜▽゜)o☆

#### 1.3.2 重参数技巧

然后还有一个小点，重参数技巧（reparameterization trick）。这个对扩散模型公式推导有大用！

我们是从$p(Z|X_k)$中采样出$Z_k$，没问题吧。我们知道这是正态分布的，但是其实均值和方差都是模型算出来，之后还要通过backward优化这些参数，采样这个动作是不可导的，但是结果是可导的。

所以我们从$\mathcal{N}(\mu,\sigma^2)$中采样一个$Z$，就相当于从标准正态分布$\mathcal{N}(0,I)$中采样一个$\epsilon$，然后让$Z=\mu + \epsilon \times \sigma$. 大概就是这个意思。这段话有大用！

### 1.4 负对数似然

这个在后面求loss函数的时候会涉及到。

 #### 1.4.1 似然函数

似然（likelihood）针对的是影响概率的位置参数，根据观察结果，来估计概率模型的参数。

数学表示就是：假设$X$是离散随机变量，其概率质量函数$p$依赖于参数$\theta$，则
$$
L(\theta | x) = p_{\theta}(x) = P_{\theta}(X = x)
$$
其中，$L(\theta|x)$就是参数$\theta$的似然函数，$x$为随机变量$X$的某一值。

#### 1.4.2 最大似然估计

最大似然估计（Maximum Likelihood Estimation, MLE）就是：

我们有一个数据分布$P_{data}(x)$，但是不知道分布的数学表达。所以就定义一个分布模型$P_G(x;\theta)$，分布由参数$\theta$决定。设$L$是分布模型$P_G(x;\theta)$的样本的似然函数，我们要求出一个$\theta$，使得含有参数$\theta$的似然函数$L$最大，也就是让我们定义的分布模型越接近数据分布。

似然函数表达式如下：
$$
L = \prod^m_{i=1}P_G(x^i;\theta)
$$

#### 1.4.3 对数似然

似然函数是很多项的乘积，取个对数是不是就相加了，计算相对更简单，求导也容易。就这么个作用。
$$
l(\theta)=\sum^m_{i=1}log \big( P_G(x^i;\theta) \big)
$$

#### 1.4.4 负对数似然 

要做loss函数的话，就是要越小越好。似然函数我们是要越大越好，所以取负，就是越小越好啦。
$$
l(\theta)= - \sum^m_{i=1}log \big( P_G(x^i;\theta) \big)
$$

## 2 扩散模型

> 好！可算是到正文部分了，还在嘛(\*≧︶≦))(￣▽￣* )ゞ

附上一篇经典论文：[Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf)

<center class="half">
  <img src="/assets/img/scientific_research/扩散模型.assets/image-20231128165916608.png" height="400"/>&emsp;
</center>

> 一些个参考：
>
> - 视频：[54、Probabilistic Diffusion Model概率扩散模型理论与完整PyTorch代码详细解读\_哔哩哔哩\_bilibili](https://www.bilibili.com/video/BV1b541197HX/?spm_id_from=333.337.search-card.all.click&vd_source=886b79dff7fd3ea9c414872fed24df59)
> - 文字：[扩散模型之DDPM - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/563661713)
>
> 建议视频文字同时看，视频没跟上或者讲的不详细的，看文字版，手边放个演草纸推导一下。然后你会发现虽然不知道到底有没有用，但是推出来的感觉针布戳！我这里就不过多的涉及公式推导了，~~因为打公式打起来真的要命啊~~。建议自己去看给的参考链接，很详细。感觉这些公式对于理解代码来说也挺重要的。
>
> 我如果我没有理解错的话，所有的公式推导和化简的最终形态，就是最后的损失函数，这样就很简单合理地翻译成代码来训练模型啦！感觉公式推导化简完全就是理论抽象成简单的公式的过程，这就是数学的魅力吗ヽ(✿°▽ﾟ)ノ。

扩散模型的过程其实和VAE有点像。整体思路就是先给数据加噪声，反反复复加噪声，让其接近正态分布，然后再还原回来。就这么个事！好！结束（bushi

理论上，模型主要分成两个部分，**前向过程（forward process）**和**反向过程(reverse process)**。前向过程（扩散过程）就是给数据$x_0$加噪，让其充分接近正态分布图像$x_T$（对应着下面这张图的从右向左过程）；反向过程（逆扩散过程）就是去噪的过程，逐渐生成回$x_0$（从左向右的过程）。

<center class="half">
  <img src="/assets/img/scientific_research/扩散模型.assets/image-20231128210341142.png" height="400"/>&emsp;
</center>

有几个点可以留意一下：

- 扩散过程中的当前图是由上一时间点的图像加噪来的（所有都是满足正态分布的）。但是由于遵循**马尔可夫假设原则**，实际计算上可以直接由$x_0$计算出来。
- 反向过程，就是我们需要建立模型的环节，就是我们需要的生成模型了。那这个模型其实是**拟合一个正态分布**。当然优化的话，就是让模型去拟合扩散过程的正态分布啦，就要用到KL散度。
- 优化目标。这个推导相当之复杂（开摆！）。总之通过一系列假设、化简、代换，最后由计算两个模型的KL散度，转化为计算噪声的拟合程度。也就是说由预测正态分布的均值、方差这些转化成了**预测噪声**。（这是咋想出来的？😔，只能说，🐂🍺！预测噪声这个点知道了的话，代码就能理解了。

### 2.1 扩散过程

扩散过程就是给数据一直加高斯噪声，直到这个数据变成了随机噪声。

具体的数学实现是怎么计算的呢！嘿！嘿！嘿！准备好了嘛（奸笑。

那先进行一些相关说明。我们假设原始数据$x_0$是满足分布$q(x_0)$的，也就是$x \sim q(x_0)$。因为是一遍遍加噪声嘛，所以我们设总共要$T$步的扩散过程，每一步都要对上一步的数据$x_{t-1}$增加噪声，这个噪声的标准差$\sigma$是由一个固定值$\beta_t$来确定的，均值$\mu$是由固定值$\beta_t$和t时刻的数据$x_t$确定的 ，所以加噪的操作就是
$$
q(x_t|x_{t-1})=\mathcal{N}\big(x_t;\sqrt{1-\beta_t}x_{t-1}, \beta_tI\big)
$$
整个过程是满足马尔可夫链的，所以就可以得到下面这个公式（提醒你一下，用到了[1.1.2](#1.1.2 基于马尔科夫假设的条件概率)的公式）
$$
q(x_{1:T}|x_0) = \prod^T_{t=1}q(x_t|x_{t-1})
$$
然后，精彩的来了！先说结论，**$x_t$其实可以直接用$x_0$算出来**！

还记得重参数技巧嘛，我们可以将上面这个加噪的过程翻译一下:
$$
\begin{aligned}
x_t &= \sqrt{1-\beta_t}x_{t-1} + \sqrt{\beta_t}\epsilon_{t-1} \\
&= \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_{t-1}
\end{aligned}
$$
这里为了方便之后的表达式书写，所以设$a_t=1-\beta_t$，到这里没问题吧？

然后递推公式，t-1时刻也可以用t-2时刻的来表示。具体的推导过程不多说，直接上结论，反正最后化简成这玩应儿了
$$
\begin{aligned}
x_t &= \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_{t-1} \\
&= \cdots \\
&= \sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}\epsilon
\end{aligned}
$$
所以就可以用分布$q(x_t|x_0)$来表示啦，然后翻译一下：
$$
q(x_t|x_0) = \mathcal{N}\big(x_t;\sqrt{\overline{\alpha_t}}x_0, (1-\overline{\alpha_t})I\big)
$$
是不是很神奇！是！这个先放在这里，后面有用。

正向的部分结束！

### 2.2 反向过程

#### 2.2.1 训练网络建模

逆扩散过程就是从高斯噪声中恢复原始数据，也就是生成数据的过程。我们用神经网络来估计这些分布。反向过程也是一个马尔科夫链过程哦。那我们可以定义一个分布模型：
$$
p_\theta(x_{0:T})=p(x_T) \prod^T_{t=1} p_\theta (x_{t-1}|x_t) 
\\
p_\theta(x_{t-1}|x_t) = \mathcal{N} \big(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t)\big), \quad p(x_T) = \mathcal{N}(x_T; 0,I)
$$
这里的$p(x_T) = \mathcal{N}(x_T;0,I)$，$p_\theta(x_{t-1}|x_t)$是参数化的高斯分布，其均值和方差就是$\mu_\theta(x_t, t)$和$\Sigma_\theta(x_t, t)$，也就是我们要训练的网络啦。

好！记住它！下一个环节！

#### 2.2.2 对比用的标准分布

还记得正向过程中我们留下的式子吧，就是分布$q(x_t|x_0)$。你想想看，我们建好的模型$p_\theta(x_{t-1}|x_t)$的意义是什么？是不是由$x_t$推到$x_{t-1}$的概率，那我们需要的标准是不是也得是由$x_t$推到$x_{t-1}$的概率，所以应该是$q(x_{t-1}|x_t)$啊。

可是现在只有$q(x_t|x_0)$，怎么办？算啊！怎么算？马尔科夫链！直接算不了$q(x_{t-1}|x_t)$，我们可以求$q(x_{t-1}|x_t,x_0)$嘛！
$$
\begin{aligned}
q(x_{t-1}|x_t, x_0) &= q(x_t|x_{t-1}, x_0) \frac{q(x_{t-1}|x_0)}{q(x_t|x_0)} 
\\
&\propto exp\bigg( -\frac{1}{2} \big( \frac{(x_t-\sqrt{a_t}x_{t-1})^2}{\beta_t}+\frac{(x_{t-1}-\sqrt{\overline{a}_{t-1}}x_0)^2}{1-\overline{\alpha}_{t-1}}-\frac{(x_t-\sqrt{\overline{\alpha}_t}x_0)^2}{1-\overline{\alpha}_t} \big) \bigg) 
\\
&= exp \bigg( -\frac{1}{2} \big( (\frac{\alpha_t}{\beta_t}+\frac{1}{1-\overline{\alpha}_{t-1}}) x^2_{t-1} - (\frac{2\sqrt{\alpha_t}}{\beta_t}x_t+\frac{2\sqrt{\overline{\alpha}_{t-1}}}{1-\overline{\alpha}_{t-1}}x_0)x_{t-1}+C(x_t, x_0) \big) \bigg)
\end{aligned}
$$
这里C与$x_{t-1}$无关，所以忽略，看成常量就行。所以exp大括号里面就可以看成是一个关于$x_{t-1}$的一元二次的式子了。高中数学的记忆还在不在？配方会不会？就是$ax^2+bx=a(x+\frac{b}{2a})^2+C$，把上面配个方，就成了个正态分布的形式！整理化简一下，这个正态分布$q(x_{t-1}|x_t,x_0)$的均值和方差就是：
$$
\widetilde{\mu}_t(x_t, x_0) = \frac{\sqrt{\alpha_t}(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t} x_t +\frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t} x_0
\\
\widetilde{\beta}_t = \frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_t} \beta_t
$$
还可以再化简一步，还记得$x_t$可以用$x_0$表示的那个环节吗？是不是$x_0$也可以用$x_t$表示一下，就是移个项再除一下系数那种。就是这样：
$$
x_t = \sqrt{\overline{\alpha_t}}x_0+\sqrt{1-\overline{\alpha_t}}\epsilon
\\
\downarrow
\\
x_0 = \frac{1}{\sqrt{\overline{\alpha}_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\epsilon_t)
$$
那均值里面有$x_0$，所以就可以进一步化简：(把方差也放过来，方便之后观看)
$$
\widetilde{\mu}_t = \frac{1}{\sqrt{\alpha_t}} \bigg( x_t - \frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon_t \bigg)
\\
\widetilde{\beta}_t = \frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_t} \beta_t
$$
$q(x_{t-1}|x_t, x_0)$也可以写成正态分布的表达式：
$$
q(x_{t-1}|x_t, x_0) = \mathcal{N}(x_{t-1};\widetilde{\mu}
_t(x_t, x_0),\widetilde{\beta}_tI)
$$
好！这下我们有了训练模型$p_\theta(x_{t-1}|x_t)$和模型的标准参考$q(x_{t-1}|x_t, x_0)$（可忽略$x_0$，因为马尔科夫链），接下来就是优化，也就是要知道loss函数是什么。

### 2.3 优化!

> 从这里开始，逐渐离谱，不想写了（阴暗爬行）我尽力整理归纳，你们尽力理解（扶额）（叹气）这些都是咋想到的呢？
>
> 前面所有的表达式，都是为了优化这步做准备。没记住没关系，要用到什么，我会再相应的地方提醒你或者重复一遍，别嫌我墨迹就行~(￣▽￣)~*

#### 2.3.1 Loss总项

首先，要用到[负对数似然函数](#1.4 负对数似然)（emmm...，这里怎么解释的都有，反正最后推导过程都一样，问题不大）。

我们在负对数似然函数的基础上，加上KL散度，这样有了一个上界，上界小了，负对数似然函数也能小。
$$
\begin{aligned}
-\log{p_\theta(x_0)} &\leq -\log{p_\theta(x_0)}+D_{KL}(q(x_{1:T}|x_0)||p_\theta(x_{1:T}|x_0))
\\
&= \cdots
\\
&=\mathbb{E}_q \big[ \log{\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}} \big]
\\
&=L_T + \sum^T_{t=2} L_{t-1} - L_0
\end{aligned}
$$
然后我们让
$$
L = L_{VLB}= \mathbb{E}_{q(x_{1:T}|x_0)}\big[ \log{\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}} \big]
$$
然后就是展开、化简。
$$
\begin{aligned}
L &= \mathbb{E}_{q(x_{1:T}|x_0)}\big[ \log{\frac{q(x_{1:T}|x_0)}{p_\theta(x_{0:T})}} \big]
\\
&= \cdots
\\
&= \underbrace{D_{KL} \big( q(x_T|x_0) || p_\theta(x_T) \big)}_{L_T} + \sum^{T}_{t=2} \underbrace{\mathbb{E}_{q(x_t|x_0)} \big[ D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t)) \big]}_{L_{t-1}} \underbrace{-\mathbb{E}_{q(x_1|x_0)} \log{p_\theta(x_0|x_1)}}_{L_0}
\end{aligned}
$$
过程你别管，就是化简（偷懒）。反正就是最后剩下着三个部分。
$$
\begin{aligned}
& L_T = D_{KL} \big( q(x_T|x_0) || p_\theta(x_T) \big) 
\\
& L_{t-1} = \mathbb{E}_{q(x_t|x_0)} \big[ D_{KL}(q(x_t-1|x_t,x_0)||p_\theta(x_{t-1}|x_t)) \big]
\\
& L_0 = -\mathbb{E}_{q(x_1|x_0)} \log{p_\theta(x_0|x_1)}
\end{aligned}
$$
接下来，这三项，就分别求呗。

#### 2.3.2 $L_0$分项

> 这部分没太看懂＞︿＜，等我去研究研究扩散模型的的代码，再回来补充。
>
> 论文中最后对loss进行了化简，没有算上这个部分，所以可以暂时忽略这一趴。

$L_0$这部分相当于从连续空间到离散空间的解码loss，优化的是对数似然，$L_0$可以用估计的$\mathcal{N}(x_0;\mu_\theta(x_1, 1),\sigma^2_1I)$来构建一个离散化的解码器来计算：
$$
\begin{aligned}
p_{\theta}(x_0|x_1) &= \prod^D_{i=1} \int_{\delta_{-}(x_0^i)}^{\delta_{+}(x_0^i)} \mathcal{N}(x_0; \mu_\theta^i(x_1,1),\sigma_1^2)dx
\\
\delta_{+}(x) &= 
\begin{cases}
\infty & if \quad x = 1 \\
x+\frac{1}{255} & if \quad x < 1 \\
\end{cases}
\\
\delta_{-}(x) &= 
\begin{cases}
-\infty & if \quad x = -1 \\
x - \frac{1}{255} & if \quad x > -1 \\
\end{cases}
\end{aligned}
$$

#### 2.3.3 $L_T$分项

回忆！$q(x_T|x_0)$和$p_\theta(x_T)$是啥？
$$
q(x_t|x_0) = \mathcal{N}\big(x_t;\sqrt{\overline{\alpha_t}}x_0, (1-\overline{\alpha_t})I\big)
\\
p(x_T) = \mathcal{N}(x_T;0,I)
$$
这里DDPM论文里是将方差固定了，所以$L_T$这项就是个常数了。

#### 2.3.4 $L_{t-1}$小项



这里，有意思的来了，就是那个把预测均值转化成预测噪声的骚操作！这个经过实验证明，确实预测噪声要比预测均值效果要好。嗯，神奇！

还是回忆！$q(x_{t-1}|x_t,x_0)$和$p_\theta(x_{t-1}|x_t)$是啥?
$$
q(x_{t-1}|x_t, x_0) = \mathcal{N}(x_{t-1};\widetilde{\mu}
_t(x_t, x_0),\widetilde{\beta}_tI)
\\
p_\theta(x_{t-1}|x_t) = \mathcal{N} \big(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t)\big)
$$
求它俩的KL散度。这里论文里是将$p_\theta(x_{t-1}|x_t)$的方差$\Sigma_\theta(x_t, t)$设置成一个与$\beta$相关的常数了，还记得[两个正态分布的KL散度](#1.2.2 高斯分布的KL散度)怎么计算吧？
$$
KL(p,q)=log\frac{\sigma_2}{\sigma_1}+\frac{\sigma_1^2+(\mu_1-\mu_2)^2}{2\sigma_2^2}-\frac{1}{2}
$$
代进去，化简：
$$
D_{KL}(q(x_{t-1}|x_t,x_0)||p_\theta(x_{t-1}|x_t)) = \frac{1}{2\sigma^2_t}||\widetilde{\mu}
_t(x_t, x_0) - \mu_{\theta}(x_t, t)||^2 + C
$$
所以
$$
L_{t-1}=\mathbb{E}_{q(x_t|x_0)} \big[ \frac{1}{2\sigma^2_t}||\widetilde{\mu}_t(x_t, x_0) - \mu_{\theta}(x_t, t)||^2 \big] + C
$$
还记得$\widetilde{\mu}_t(x_t, x_0)$是可以进一步化简的吧，就是$x_0$也可以用$x_t$表示的那个：
$$
x_0 = \frac{1}{\sqrt{\overline{\alpha}_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\epsilon_t)
\\
\widetilde{\mu}_t = \frac{1}{\sqrt{\alpha_t}} \bigg( x_t - \frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon_t \bigg)
$$
写标准一点的话，就是
$$
\widetilde{\mu}_t(x_t, x_0) = \frac{1}{\sqrt{\alpha_t}} \bigg( x_t(x_0,\epsilon) - \frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon_t \bigg)
$$
先放一边！还有一项$\mu_{\theta}(x_t, t)$，这个是我们建的模$p_\theta(x_{t-1}|x_t)$的均值。这里作者的骚操作就来了，$\widetilde{\mu}_t(x_t, x_0)$最后是可以用$x_t$和随机变量$\epsilon$表示，对于我们的模型来说，$x_t$是什么？是不是我前向的时候加噪得到的乱糟的图像，所以是已知的，但是噪声模型它不知道啊，所以我们是不是可以预测一个噪声去拟合设立的标准分布！也就相当于用均值去拟合，对不对！

所以：
$$
\begin{aligned}
\mu_{\theta}(x_t, t) &= \widetilde{\mu}_t(x_t, x_0(x_t,\epsilon_{\theta}))
\\
&= \widetilde{\mu}_t \bigg( x_t, \frac{1}{\sqrt{\overline{\alpha}_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\epsilon_{\theta}(x_t)) \bigg)
\\
&= \frac{1}{\sqrt{\alpha}_t} \bigg( x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon_{\theta}(x_t,t) \bigg) 
\end{aligned}
$$
这俩代进去：
$$
\begin{aligned}
L_{t-1} - C &= \mathbb{E}_{x_0,\epsilon} \bigg[ \frac{1}{2\sigma^2_t}|| \frac{1}{\sqrt{\alpha_t}} \bigg( x_t(x_0,\epsilon) - \frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon_t \bigg) - \frac{1}{\sqrt{\alpha}_t} \bigg( x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\epsilon_{\theta}(x_t,t) \bigg) ||^2 \bigg] 
\\
&= \mathbb{E}_{x_0,\epsilon} \bigg[ \frac{\beta^2_t}{2\sigma^2_t \alpha_t(1-\overline{\alpha}_t)} || \epsilon - \epsilon_{\theta}(\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1-\overline{\alpha}_t} \epsilon, t) ||^2 \bigg]
\end{aligned}
$$

#### 2.3.5 整理总结

论文里，作者又进一步简化，直接系数不要了，化简成这样：
$$
L_{simple}(\theta)= \mathbb{E}_{x_0,\epsilon} \bigg[ || \epsilon - \epsilon_{\theta}(\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1-\overline{\alpha}_t} \epsilon, t) ||^2 \bigg]
$$




> 扩散模型理论部分就先写到这里吧！我去看看代码ヽ(゜▽゜　)－C<(/;◇;)/~
>
> 感谢观看！
